{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pressing-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sensebert import SenseBert\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aggressive-expense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[-0.6506447 , -0.16967805,  0.14072387, ..., -0.37985668,\n",
      "          0.82097167, -0.1802699 ],\n",
      "        [-0.43151152,  0.04906671,  0.33647287, ..., -0.7424973 ,\n",
      "          0.86205894,  0.56475866],\n",
      "        [ 0.11911742,  0.30231696,  0.01322322, ..., -0.9130749 ,\n",
      "         -0.04722284,  0.52869815],\n",
      "        ...,\n",
      "        [-0.27734977, -0.2632196 , -0.42078534, ..., -1.3844373 ,\n",
      "         -0.25757593,  0.48685086],\n",
      "        [ 0.3355558 , -0.24686146,  0.09991715, ..., -0.94355595,\n",
      "          0.23015074,  0.49161816],\n",
      "        [-0.46015036, -0.2328133 , -0.19267169, ..., -0.4300249 ,\n",
      "          0.7341133 ,  0.20681112]],\n",
      "\n",
      "       [[-0.31325674, -0.06467588,  0.38356358, ..., -0.3004378 ,\n",
      "          0.17605749, -0.11610046],\n",
      "        [-0.2908376 ,  0.7626818 , -0.16345486, ..., -1.0970807 ,\n",
      "          0.07459535,  0.1260822 ],\n",
      "        [-0.189485  , -0.27419227, -0.97271645, ..., -1.5522854 ,\n",
      "         -0.7494767 ,  0.2617209 ],\n",
      "        ...,\n",
      "        [ 0.49235207,  0.49432755,  0.8935569 , ..., -0.87816864,\n",
      "         -0.5887735 ,  0.39217442],\n",
      "        [ 0.49235207,  0.49432755,  0.8935569 , ..., -0.87816864,\n",
      "         -0.5887735 ,  0.39217442],\n",
      "        [ 0.49235207,  0.49432755,  0.8935569 , ..., -0.87816864,\n",
      "         -0.5887735 ,  0.39217442]]], dtype=float32), array([[[ -5.5944786,  -6.2393374,  -8.051867 , ...,  -7.181358 ,\n",
      "          -7.573848 ,  -7.1600924],\n",
      "        [ -5.8176384,  -7.798347 ,  -8.5686655, ...,  -6.9843345,\n",
      "          -9.67043  ,  -8.279802 ],\n",
      "        [ -8.659028 ,  -8.332843 ,  -6.907177 , ...,  -8.8720455,\n",
      "         -14.847308 ,  -9.858175 ],\n",
      "        ...,\n",
      "        [ -4.3942575,  -4.1176167,  -2.7474983, ...,  -3.7633631,\n",
      "          -5.615272 ,  -1.3877914],\n",
      "        [-12.572775 , -12.253625 , -10.031771 , ..., -13.267053 ,\n",
      "         -10.741309 , -11.469531 ],\n",
      "        [ -6.7309456,  -7.5104785,  -8.14249  , ...,  -7.0845776,\n",
      "          -7.7998605,  -7.775854 ]],\n",
      "\n",
      "       [[ -3.8346078,  -5.0683475,  -6.0879374, ...,  -8.074416 ,\n",
      "          -4.5884247,  -5.993818 ],\n",
      "        [ -6.208733 ,  -6.737432 ,  -8.602117 , ...,  -9.779804 ,\n",
      "          -8.28855  ,  -8.546753 ],\n",
      "        [ -7.3407555,  -8.551355 ,  -7.601185 , ...,  -6.7584243,\n",
      "          -7.9945903,  -8.237076 ],\n",
      "        ...,\n",
      "        [ -4.1806297,  -4.1669526,  -3.3886673, ...,  -3.8825984,\n",
      "          -6.218793 ,  -4.0451827],\n",
      "        [ -4.1806297,  -4.1669526,  -3.3886673, ...,  -3.8825984,\n",
      "          -6.218793 ,  -4.0451827],\n",
      "        [ -4.1806297,  -4.1669526,  -3.3886673, ...,  -3.8825984,\n",
      "          -6.218793 ,  -4.0451827]]], dtype=float32), array([[[  2.1078227 ,  -2.366833  ,  -3.438189  , ...,   0.17055741,\n",
      "          -3.8016815 , -13.136661  ],\n",
      "        [  2.16635   ,  -0.90330917,  -3.6853213 , ...,   0.28369123,\n",
      "          -4.124755  , -11.80388   ],\n",
      "        [ -1.6003219 ,  -4.63372   ,  -3.1072948 , ...,   4.4284887 ,\n",
      "          -5.989497  , -17.122843  ],\n",
      "        ...,\n",
      "        [ -1.5580605 ,  -2.1506884 ,  -7.3997307 , ...,  -0.5038611 ,\n",
      "          -5.459522  , -12.0384865 ],\n",
      "        [  2.7965667 ,  -0.87508756,  -4.6054406 , ...,   1.0584024 ,\n",
      "          -4.05951   ,  -9.92234   ],\n",
      "        [  2.40099   ,  -2.2683191 ,  -4.4096894 , ...,   0.7711822 ,\n",
      "          -4.573482  , -14.020867  ]],\n",
      "\n",
      "       [[  1.8336463 ,  -0.4710862 ,  -8.430371  , ...,  -0.4152391 ,\n",
      "          -5.4928217 , -13.319265  ],\n",
      "        [  1.8752311 ,   0.6232299 , -11.2368965 , ...,  -0.182125  ,\n",
      "          -6.350383  , -13.569507  ],\n",
      "        [ -2.2508976 ,  -3.0991871 ,  -8.400947  , ...,  -0.73573184,\n",
      "          -4.8958797 , -12.00843   ],\n",
      "        ...,\n",
      "        [  2.1647956 ,  -2.7917752 ,  -7.4594927 , ...,  -1.6035023 ,\n",
      "          -4.0689683 , -12.377625  ],\n",
      "        [  2.1647956 ,  -2.7917752 ,  -7.4594927 , ...,  -1.6035023 ,\n",
      "          -4.0689683 , -12.377625  ],\n",
      "        [  2.1647956 ,  -2.7917752 ,  -7.4594927 , ...,  -1.6035023 ,\n",
      "          -4.0689683 , -12.377625  ]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    sensebert_model = SenseBert(\"sensebert-base-uncased\", session=session)  # or sensebert-large-uncased\n",
    "    input_ids, input_mask = sensebert_model.tokenize([\"I went to the store to buy some groceries.\", \"The store was closed.\"])\n",
    "    model_outputs = sensebert_model.run(input_ids, input_mask)\n",
    "    contextualized_embeddings, mlm_logits, supersense_logits = model_outputs  # these are NumPy arrays\n",
    "    print(model_outputs)\n",
    "    print(sensebert_model.tokenizer.convert_ids_to_senses([np.argmax(supersense_logits[0][9])]))\n",
    "    print(sensebert_model)\n",
    "    print(supersense_logits.shape)\n",
    "    print(sensebert_model.tokenize([\"I went to the store to buy some groceries.\", \"The store was closed.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "similar-arlington",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "belabor\n",
      "belabor\n",
      "['sentenc', 'sentenc', 'excus', 'excus', 'excus']\n",
      "buy\n",
      "bought\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "print(WordNetLemmatizer().lemmatize('belabor', pos=\"V\".lower()))\n",
    "print(WordNetLemmatizer().lemmatize('belabored', pos=\"v\"))\n",
    "\n",
    "ps = PorterStemmer()\n",
    "words = [\"sentence\", \"sentences\", \"excuse\", \"excused\", \"excuses\"]\n",
    "\n",
    "words = [ps.stem(w) for w in words]\n",
    "print(words)\n",
    "\n",
    "print(ps.stem(\"buy\"))\n",
    "print(ps.stem(\"bought\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "excess-apollo",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the known model 'sensebert-base-uncased'\n",
      "INFO:tensorflow:Restoring parameters from gs://ai21-public-models/sensebert-base-uncased/variables/variables\n",
      "Loading the known tokenizer 'sensebert-base-uncased'\n",
      "Room and board . He nailed boards across the windows .\n",
      "board boards\n",
      "noun.substance verb.consumption\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "Circulate a rumor . This letter is being circulated among the faculty .\n",
      "circulate circulated\n",
      "verb.communication verb.change\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "Hook a fish . He hooked a snake accidentally , and was so scared he dropped his rod into the water .\n",
      "hook hooked\n",
      "verb.contact verb.contact\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "For recreation he wrote poetry and solved crossword puzzles . Drug abuse is often regarded as a form of recreation .\n",
      "recreation recreation\n",
      "noun.act noun.act\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "Making a hobby of domesticity . A royal family living in unpretentious domesticity .\n",
      "domesticity domesticity\n",
      "noun.act noun.act\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "The child 's acquisition of language . That graphite tennis racquet is quite an acquisition .\n",
      "acquisition acquisition\n",
      "noun.act noun.act\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "There was no meeting of minds . The meeting elected a chairperson .\n",
      "meeting meeting\n",
      "noun.act noun.group\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "They swam in the nude . The marketing rule ' nude sells ' spread from verbal to visual mainstream media in the 20th century .\n",
      "nude nude\n",
      "adj.all adj.all\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "He left an indelible mark on the American theater . It was in London that he made his mark .\n",
      "mark mark\n",
      "verb.contact noun.person\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "Conditioning is a form of learning by association . Many close associations with England .\n",
      "association associations\n",
      "noun.cognition noun.state\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "The alkaline inclination of the local waters . An inclination of his head indicated his agreement .\n",
      "inclination inclination\n",
      "noun.attribute noun.attribute\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "Glaze the bread with eggwhite . The potter glazed the dishes .\n",
      "glaze glazed\n",
      "verb.change verb.change\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "An amendment to piggyback the current law . He piggybacked her child so she could see the show .\n",
      "piggyback piggybacked\n",
      "verb.change verb.motion\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "To pick rags . Do n't always pick on your little brother .\n",
      "pick pick\n",
      "verb.cognition verb.cognition\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "Belabor the obvious . She was belabored by her fellow students .\n",
      "belabor belabored\n",
      "verb.communication verb.communication\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "Bell cows . Who will bell the cat ?\n",
      "bell bell\n",
      "noun.artifact noun.person\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "He took the manuscript in both hands and gave it a mighty tear . There were big tears rolling down Lisa 's cheeks .\n",
      "tear tears\n",
      "noun.act verb.body\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "Kill the engine . He killed the ball .\n",
      "kill killed\n",
      "verb.social verb.social\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "Analyze your real motives . The inspector analyzed the building 's soundness .\n",
      "analyze analyzed\n",
      "verb.cognition verb.cognition\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "Did you ever lecture at Harvard ? She lectured to the class about her travels .\n",
      "lecture lectured\n",
      "verb.communication verb.communication\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "A rehearsal will be held the day before the wedding . He missed too many rehearsals .\n",
      "rehearsal rehearsals\n",
      "noun.act noun.act\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "We decided to forge ahead with our plans even though our biggest underwriter backed out . He forged ahead .\n",
      "forge forged\n",
      "noun.artifact adj.all\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "The belief that the world is flat is a falsity . Argument could not determine its truth or falsity .\n",
      "falsity falsity\n",
      "noun.communication noun.communication\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "An assurance of help when needed . His assurance in his superiority did not make him popular .\n",
      "assurance assurance\n",
      "noun.communication noun.cognition\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "A branch of Congress . We have branches in all major suburbs .\n",
      "branch branches\n",
      "noun.object noun.artifact\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "He tried to clear his head of the whisky fuzz . Peach fuzz .\n",
      "fuzz fuzz\n",
      "noun.cognition noun.person\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "I can not risk smoking . Why risk your life ?\n",
      "risk risk\n",
      "verb.social noun.attribute\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "The chemistry of indigo . The chemistry of iron .\n",
      "chemistry chemistry\n",
      "noun.relation noun.cognition\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "“ Among other native delicacies , they give you fresh char . ” . “ I had to scrub the kitchen today , because the char could n't come ” .\n",
      "char char\n",
      "verb.change verb.weather\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "This situation developed in response to events in Africa . His responses have slowed with age .\n",
      "response responses\n",
      "noun.attribute noun.act\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "That thing is a poor excuse for a gingerbread man . Has n't anyone taught you how to bake ? He 's a sorry excuse of a doctor .\n",
      "excuse excuse\n",
      "noun.cognition noun.cognition\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "He sought release from his bondage to Satan . A self freed from the bondage of time .\n",
      "bondage bondage\n",
      "noun.state noun.state\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "162 115 204 157\n"
     ]
    }
   ],
   "source": [
    "dev_data = []\n",
    "with open(\"WiC_dataset/dev/dev.data.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        l = line.strip().split(\"\\t\")\n",
    "        key, pos, locs, s1, s2 = l[0], l[1], l[2], l[3], l[4]\n",
    "        loc1, loc2 = locs.split(\"-\")\n",
    "        dev_data.append((key, s1, s2, loc1, loc2, pos))\n",
    "\n",
    "dev_gold = []\n",
    "with open(\"WiC_dataset/dev/dev.gold.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    dev_gold = [\"True\" if l.strip(\"\\n\") == \"T\" else \"False\" for l in lines]\n",
    "\n",
    "dev = list(zip(dev_data, dev_gold))\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "ITERATIONS = (len(dev_data) // BATCH_SIZE) + 1\n",
    "\n",
    "with tf.Session() as session:\n",
    "    sensebert_model = SenseBert(\"sensebert-base-uncased\", session=session)  # or sensebert-large-uncased\n",
    "    \n",
    "    \n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    \n",
    "    for i in range(ITERATIONS):\n",
    "        start_idx = i * BATCH_SIZE\n",
    "        end_idx = min((i+1) * BATCH_SIZE, len(dev_data))\n",
    "    #     print(start_idx, end_idx)\n",
    "        sentences = []\n",
    "        locations = []\n",
    "        target_words = []\n",
    "        poses = []\n",
    "        for j in range(start_idx, end_idx):\n",
    "            target_words.append(dev_data[j][0])\n",
    "            target_words.append(dev_data[j][0])\n",
    "            sentences.append(dev_data[j][1])\n",
    "            sentences.append(dev_data[j][2])\n",
    "            locations.append(dev_data[j][3])\n",
    "            locations.append(dev_data[j][4])\n",
    "            poses.append(dev_data[j][5].lower())\n",
    "            poses.append(dev_data[j][5].lower())\n",
    "    #     print(sentences)\n",
    "        input_ids, input_mask = sensebert_model.tokenize(sentences)\n",
    "\n",
    "\n",
    "        found_indices = []\n",
    "        found_words = []\n",
    "        ## check that loc1, loc2 are good positions\n",
    "        for idx, input_id in enumerate(input_ids):\n",
    "            tokenized = sensebert_model.tokenizer.convert_ids_to_tokens(input_id)\n",
    "            target_idx = int(locations[idx])+1\n",
    "            found_indices.append(target_idx)\n",
    "            found_words.append(tokenized[target_idx])\n",
    "\n",
    "    #     print(found_indices)\n",
    "    #     print(found_words)\n",
    "\n",
    "        for j in range(0, len(sentences), 2):\n",
    "\n",
    "            if WordNetLemmatizer().lemmatize(found_words[j], pos=poses[j]) != WordNetLemmatizer().lemmatize(found_words[j+1], pos=poses[j]):\n",
    "\n",
    "                ## lemmatize sentences, and keyword\n",
    "                tokenized_1 = sensebert_model.tokenizer.convert_ids_to_tokens(input_ids[j])\n",
    "                tokenized_2 = sensebert_model.tokenizer.convert_ids_to_tokens(input_ids[j+1])\n",
    "\n",
    "                tokenized_1_stem = [ps.stem(w) for w in tokenized_1]\n",
    "                tokenized_2_stem = [ps.stem(w) if w!= \"bought\" else \"buy\" for w in tokenized_2]\n",
    "\n",
    "                key_word = ps.stem(target_words[j])\n",
    "\n",
    "    #             print(target_words[j])\n",
    "    #             print(key_word)\n",
    "    #             print(tokenized_1, tokenized_2)\n",
    "\n",
    "    #             print(tokenized_1.index(key_word))\n",
    "    #             print(tokenized_2.index(key_word))\n",
    "\n",
    "                found_indices[j] = tokenized_1_stem.index(key_word)\n",
    "                found_indices[j+1] = tokenized_2_stem.index(key_word)\n",
    "                found_words[j] = tokenized_1[found_indices[j]]\n",
    "                found_words[j+1] = tokenized_2[found_indices[j+1]]\n",
    "\n",
    "                ## find keyword in lemmatized sentences\n",
    "\n",
    "    #             print(target_words[j])\n",
    "    #             print(target_words[j+1])\n",
    "\n",
    "    #     print(found_indices)\n",
    "    #     print(found_words)\n",
    "#         print(len(sentences))\n",
    "        input_ids, input_mask = sensebert_model.tokenize(sentences)\n",
    "        model_outputs = sensebert_model.run(input_ids, input_mask)\n",
    "        contextualized_embeddings, mlm_logits, supersense_logits = model_outputs  # these are NumPy arrays\n",
    "#         print(supersense_logits.shape)\n",
    "        \n",
    "        for j in range(0, len(sentences), 2):\n",
    "            \n",
    "            pred_1 = sensebert_model.tokenizer.convert_ids_to_senses([np.argmax(supersense_logits[j][found_indices[j]])])\n",
    "            pred_2 = sensebert_model.tokenizer.convert_ids_to_senses([np.argmax(supersense_logits[j+1][found_indices[j+1]])])\n",
    "            \n",
    "            if start_idx==0:\n",
    "                print(sentences[j], sentences[j+1])\n",
    "                print(found_words[j], found_words[j+1])\n",
    "                print(pred_1[0], pred_2[0])\n",
    "                print(f'prediction: {pred_1[0]==pred_2[0]}')\n",
    "                print(f'actual: {dev_gold[start_idx+j//2]}')\n",
    "                print()\n",
    "            \n",
    "            if pred_1[0] == pred_2[0]:\n",
    "                if dev_gold[start_idx+j//2] == \"True\":\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FP += 1\n",
    "            else:\n",
    "                if dev_gold[start_idx+j//2] == \"True\":\n",
    "                    FN += 1\n",
    "                else:\n",
    "                    TN += 1\n",
    "        \n",
    "\n",
    "    print(TP, FP, TN, FN)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "imperial-senegal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the known model 'sensebert-large-uncased'\n",
      "INFO:tensorflow:Restoring parameters from gs://ai21-public-models/sensebert-large-uncased/variables/variables\n",
      "Loading the known tokenizer 'sensebert-large-uncased'\n",
      "Room and board . He nailed boards across the windows .\n",
      "board boards\n",
      "verb.consumption verb.stative\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "Circulate a rumor . This letter is being circulated among the faculty .\n",
      "circulate circulated\n",
      "verb.communication verb.change\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "Hook a fish . He hooked a snake accidentally , and was so scared he dropped his rod into the water .\n",
      "hook hooked\n",
      "noun.act adj.all\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "For recreation he wrote poetry and solved crossword puzzles . Drug abuse is often regarded as a form of recreation .\n",
      "recreation recreation\n",
      "noun.act noun.act\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "Making a hobby of domesticity . A royal family living in unpretentious domesticity .\n",
      "domesticity domesticity\n",
      "noun.act noun.act\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "The child 's acquisition of language . That graphite tennis racquet is quite an acquisition .\n",
      "acquisition acquisition\n",
      "noun.possession noun.possession\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "There was no meeting of minds . The meeting elected a chairperson .\n",
      "meeting meeting\n",
      "noun.act noun.act\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "They swam in the nude . The marketing rule ' nude sells ' spread from verbal to visual mainstream media in the 20th century .\n",
      "nude nude\n",
      "noun.person noun.person\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "He left an indelible mark on the American theater . It was in London that he made his mark .\n",
      "mark mark\n",
      "noun.person noun.communication\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "Conditioning is a form of learning by association . Many close associations with England .\n",
      "association associations\n",
      "noun.process noun.process\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "The alkaline inclination of the local waters . An inclination of his head indicated his agreement .\n",
      "inclination inclination\n",
      "noun.cognition noun.attribute\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "Glaze the bread with eggwhite . The potter glazed the dishes .\n",
      "glaze glazed\n",
      "verb.perception verb.perception\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "An amendment to piggyback the current law . He piggybacked her child so she could see the show .\n",
      "piggyback piggybacked\n",
      "verb.change verb.contact\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "To pick rags . Do n't always pick on your little brother .\n",
      "pick pick\n",
      "verb.change noun.artifact\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "Belabor the obvious . She was belabored by her fellow students .\n",
      "belabor belabored\n",
      "verb.social verb.communication\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "Bell cows . Who will bell the cat ?\n",
      "bell bell\n",
      "verb.contact verb.social\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "He took the manuscript in both hands and gave it a mighty tear . There were big tears rolling down Lisa 's cheeks .\n",
      "tear tears\n",
      "noun.act verb.motion\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "Kill the engine . He killed the ball .\n",
      "kill killed\n",
      "verb.consumption verb.stative\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "Analyze your real motives . The inspector analyzed the building 's soundness .\n",
      "analyze analyzed\n",
      "verb.cognition adj.all\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "Did you ever lecture at Harvard ? She lectured to the class about her travels .\n",
      "lecture lectured\n",
      "noun.act verb.communication\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "A rehearsal will be held the day before the wedding . He missed too many rehearsals .\n",
      "rehearsal rehearsals\n",
      "noun.act noun.act\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "We decided to forge ahead with our plans even though our biggest underwriter backed out . He forged ahead .\n",
      "forge forged\n",
      "verb.creation adj.all\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "The belief that the world is flat is a falsity . Argument could not determine its truth or falsity .\n",
      "falsity falsity\n",
      "noun.state noun.state\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "An assurance of help when needed . His assurance in his superiority did not make him popular .\n",
      "assurance assurance\n",
      "noun.cognition noun.cognition\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "A branch of Congress . We have branches in all major suburbs .\n",
      "branch branches\n",
      "verb.change noun.plant\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "He tried to clear his head of the whisky fuzz . Peach fuzz .\n",
      "fuzz fuzz\n",
      "noun.cognition noun.body\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "I can not risk smoking . Why risk your life ?\n",
      "risk risk\n",
      "noun.act noun.act\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "The chemistry of indigo . The chemistry of iron .\n",
      "chemistry chemistry\n",
      "noun.cognition noun.cognition\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "“ Among other native delicacies , they give you fresh char . ” . “ I had to scrub the kitchen today , because the char could n't come ” .\n",
      "char char\n",
      "verb.weather noun.person\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "This situation developed in response to events in Africa . His responses have slowed with age .\n",
      "response responses\n",
      "noun.phenomenon noun.phenomenon\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "That thing is a poor excuse for a gingerbread man . Has n't anyone taught you how to bake ? He 's a sorry excuse of a doctor .\n",
      "excuse excuse\n",
      "noun.cognition noun.communication\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "He sought release from his bondage to Satan . A self freed from the bondage of time .\n",
      "bondage bondage\n",
      "noun.state noun.state\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "179 108 211 140\n"
     ]
    }
   ],
   "source": [
    "dev_data = []\n",
    "with open(\"WiC_dataset/dev/dev.data.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        l = line.strip().split(\"\\t\")\n",
    "        key, pos, locs, s1, s2 = l[0], l[1], l[2], l[3], l[4]\n",
    "        loc1, loc2 = locs.split(\"-\")\n",
    "        dev_data.append((key, s1, s2, loc1, loc2, pos))\n",
    "\n",
    "dev_gold = []\n",
    "with open(\"WiC_dataset/dev/dev.gold.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    dev_gold = [\"True\" if l.strip(\"\\n\") == \"T\" else \"False\" for l in lines]\n",
    "\n",
    "dev = list(zip(dev_data, dev_gold))\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "ITERATIONS = (len(dev_data) // BATCH_SIZE) + 1\n",
    "\n",
    "with tf.Session() as session:\n",
    "    sensebert_model = SenseBert(\"sensebert-large-uncased\", session=session)  # or sensebert-large-uncased\n",
    "    \n",
    "    \n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    \n",
    "    for i in range(ITERATIONS):\n",
    "        start_idx = i * BATCH_SIZE\n",
    "        end_idx = min((i+1) * BATCH_SIZE, len(dev_data))\n",
    "    #     print(start_idx, end_idx)\n",
    "        sentences = []\n",
    "        locations = []\n",
    "        target_words = []\n",
    "        poses = []\n",
    "        for j in range(start_idx, end_idx):\n",
    "            target_words.append(dev_data[j][0])\n",
    "            target_words.append(dev_data[j][0])\n",
    "            sentences.append(dev_data[j][1])\n",
    "            sentences.append(dev_data[j][2])\n",
    "            locations.append(dev_data[j][3])\n",
    "            locations.append(dev_data[j][4])\n",
    "            poses.append(dev_data[j][5].lower())\n",
    "            poses.append(dev_data[j][5].lower())\n",
    "    #     print(sentences)\n",
    "        input_ids, input_mask = sensebert_model.tokenize(sentences)\n",
    "\n",
    "\n",
    "        found_indices = []\n",
    "        found_words = []\n",
    "        ## check that loc1, loc2 are good positions\n",
    "        for idx, input_id in enumerate(input_ids):\n",
    "            tokenized = sensebert_model.tokenizer.convert_ids_to_tokens(input_id)\n",
    "            target_idx = int(locations[idx])+1\n",
    "            found_indices.append(target_idx)\n",
    "            found_words.append(tokenized[target_idx])\n",
    "\n",
    "    #     print(found_indices)\n",
    "    #     print(found_words)\n",
    "\n",
    "        for j in range(0, len(sentences), 2):\n",
    "\n",
    "            if WordNetLemmatizer().lemmatize(found_words[j], pos=poses[j]) != WordNetLemmatizer().lemmatize(found_words[j+1], pos=poses[j]):\n",
    "\n",
    "                ## lemmatize sentences, and keyword\n",
    "                tokenized_1 = sensebert_model.tokenizer.convert_ids_to_tokens(input_ids[j])\n",
    "                tokenized_2 = sensebert_model.tokenizer.convert_ids_to_tokens(input_ids[j+1])\n",
    "\n",
    "                tokenized_1_stem = [ps.stem(w) for w in tokenized_1]\n",
    "                tokenized_2_stem = [ps.stem(w) if w!= \"bought\" else \"buy\" for w in tokenized_2]\n",
    "\n",
    "                key_word = ps.stem(target_words[j])\n",
    "\n",
    "    #             print(target_words[j])\n",
    "    #             print(key_word)\n",
    "    #             print(tokenized_1, tokenized_2)\n",
    "\n",
    "    #             print(tokenized_1.index(key_word))\n",
    "    #             print(tokenized_2.index(key_word))\n",
    "\n",
    "                found_indices[j] = tokenized_1_stem.index(key_word)\n",
    "                found_indices[j+1] = tokenized_2_stem.index(key_word)\n",
    "                found_words[j] = tokenized_1[found_indices[j]]\n",
    "                found_words[j+1] = tokenized_2[found_indices[j+1]]\n",
    "\n",
    "                ## find keyword in lemmatized sentences\n",
    "\n",
    "    #             print(target_words[j])\n",
    "    #             print(target_words[j+1])\n",
    "\n",
    "    #     print(found_indices)\n",
    "    #     print(found_words)\n",
    "#         print(len(sentences))\n",
    "        input_ids, input_mask = sensebert_model.tokenize(sentences)\n",
    "        model_outputs = sensebert_model.run(input_ids, input_mask)\n",
    "        contextualized_embeddings, mlm_logits, supersense_logits = model_outputs  # these are NumPy arrays\n",
    "#         print(supersense_logits.shape)\n",
    "        \n",
    "        for j in range(0, len(sentences), 2):\n",
    "            \n",
    "            pred_1 = sensebert_model.tokenizer.convert_ids_to_senses([np.argmax(supersense_logits[j][found_indices[j]])])\n",
    "            pred_2 = sensebert_model.tokenizer.convert_ids_to_senses([np.argmax(supersense_logits[j+1][found_indices[j+1]])])\n",
    "            \n",
    "            if start_idx==0:\n",
    "                print(sentences[j], sentences[j+1])\n",
    "#                 print(sensebert_model.tokenize(sentences[j]), sensebert_model.tokenize(sentences[j+1]))\n",
    "#                 print(found_indices[j], found_indices[j+1])\n",
    "                print(found_words[j], found_words[j+1])\n",
    "                print(pred_1[0], pred_2[0])\n",
    "                print(f'prediction: {pred_1[0]==pred_2[0]}')\n",
    "                print(f'actual: {dev_gold[start_idx+j//2]}')\n",
    "                print()\n",
    "            \n",
    "            if pred_1[0] == pred_2[0]:\n",
    "                if dev_gold[start_idx+j//2] == \"True\":\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FP += 1\n",
    "            else:\n",
    "                if dev_gold[start_idx+j//2] == \"True\":\n",
    "                    FN += 1\n",
    "                else:\n",
    "                    TN += 1\n",
    "        \n",
    "\n",
    "    print(TP, FP, TN, FN)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "portable-scene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the known model 'sensebert-large-uncased'\n",
      "INFO:tensorflow:Restoring parameters from gs://ai21-public-models/sensebert-large-uncased/variables/variables\n",
      "Loading the known tokenizer 'sensebert-large-uncased'\n",
      "It was a narrow defeat . The army 's only defeat .\n",
      "defeat defeat\n",
      "verb.competition noun.event\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "Groom the dogs . Sheila groomed the horse .\n",
      "groom groomed\n",
      "verb.social verb.social\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "The penetration of upper management by women . Any penetration , however slight , is sufficient to complete the offense .\n",
      "penetration penetration\n",
      "noun.attribute noun.attribute\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "We hit Detroit at one in the morning but kept driving through the night . An interesting idea hit her .\n",
      "hit hit\n",
      "verb.contact verb.motion\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "He was a man of judicial deliberation . A little deliberation would have deterred them .\n",
      "deliberation deliberation\n",
      "noun.attribute noun.attribute\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "They argued whether or not Adam had a navel . You were not supposed to show your navel on television .\n",
      "navel navel\n",
      "noun.body noun.location\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "After we leave the quarry , we intend to afforest the land and turn it into a nature reserve . Afforest the mountains .\n",
      "afforest afforest\n",
      "verb.contact verb.contact\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "Solve an old debt . Did you solve the problem ?\n",
      "solve solve\n",
      "verb.communication verb.communication\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "They offer a free hamburger with the purchase of a drink . They closed the purchase with a handshake .\n",
      "purchase purchase\n",
      "noun.phenomenon noun.phenomenon\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "Did you test the software package to ensure completeness ? The market for software is expected to expand .\n",
      "software software\n",
      "noun.communication noun.communication\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "Some details got lost in the push to get the project done . The army made a push toward the sea .\n",
      "push push\n",
      "noun.act verb.possession\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "Idaho potatoes bake beautifully . This oven bakes potatoes .\n",
      "bake bakes\n",
      "verb.stative verb.stative\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "Relieve the pressure and the stress . This pill will relieve your headaches .\n",
      "relieve relieve\n",
      "verb.social verb.social\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "In the characteristic New York style . This style of shoe is in demand .\n",
      "style style\n",
      "noun.animal verb.communication\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "Crumb the table . Crumb a cutlet .\n",
      "crumb crumb\n",
      "verb.contact verb.change\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "I include you in the list of culprits . The list includes the names of many famous writers .\n",
      "include includes\n",
      "verb.cognition verb.change\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "His dog has been his trusted companion for the last five years . Drinking companions .\n",
      "companion companions\n",
      "verb.stative noun.person\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "The actress wo n't reveal how old she is . He revealed the children found .\n",
      "reveal revealed\n",
      "verb.perception verb.perception\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "I 'm convinced that there was a presence in that building that I ca n't explain , which led to my heroic actions . She blushed in his presence .\n",
      "presence presence\n",
      "noun.cognition noun.location\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "Do n't relax your efforts now . The rules relaxed after the new director arrived .\n",
      "relax relaxed\n",
      "verb.change verb.change\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "Parity is often used to check the integrity of transmitted data . The parity of the mother must be considered .\n",
      "parity parity\n",
      "noun.attribute noun.attribute\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "To raise a wall , or a heap of stones . Raise a barn .\n",
      "raise raise\n",
      "noun.attribute verb.social\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "Suspend the particles . The prison sentence was suspended .\n",
      "suspend suspended\n",
      "verb.change verb.stative\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "To amass a treasure or a fortune . She is amassing a lot of data for her thesis .\n",
      "amass amassing\n",
      "verb.change verb.possession\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "A healthy baby born at full term . He learned many medical terms .\n",
      "term terms\n",
      "verb.communication noun.artifact\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "He 's always gotten a long leash . Kept a tight leash on his emotions .\n",
      "leash leash\n",
      "noun.act noun.act\n",
      "prediction: True\n",
      "actual: True\n",
      "\n",
      "The conversion of equations . His conversion to the Catholic faith .\n",
      "conversion conversion\n",
      "noun.communication noun.act\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "The making of measurements . It was already in the making .\n",
      "making making\n",
      "verb.stative noun.act\n",
      "prediction: False\n",
      "actual: True\n",
      "\n",
      "Before the set of sun . They played two sets of tennis after dinner .\n",
      "set sets\n",
      "noun.artifact noun.artifact\n",
      "prediction: True\n",
      "actual: False\n",
      "\n",
      "He lost the mate to his shoe . Camels hate leaving their mates .\n",
      "mate mates\n",
      "noun.artifact noun.person\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "They stared at the newcomer with a puzzled expression . His manner of expression showed how much he cared .\n",
      "expression expression\n",
      "noun.process noun.attribute\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "Rim a hat . Sugar rimmed the dessert plate .\n",
      "rim rimmed\n",
      "verb.possession adj.all\n",
      "prediction: False\n",
      "actual: False\n",
      "\n",
      "337 224 476 363\n"
     ]
    }
   ],
   "source": [
    "dev_data = []\n",
    "with open(\"WiC_dataset/test/test.data.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        l = line.strip().split(\"\\t\")\n",
    "        key, pos, locs, s1, s2 = l[0], l[1], l[2], l[3], l[4]\n",
    "        loc1, loc2 = locs.split(\"-\")\n",
    "        dev_data.append((key, s1, s2, loc1, loc2, pos))\n",
    "\n",
    "dev_gold = []\n",
    "with open(\"WiC_dataset/test/test.gold.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    dev_gold = [\"True\" if l.strip(\"\\n\") == \"T\" else \"False\" for l in lines]\n",
    "\n",
    "dev = list(zip(dev_data, dev_gold))\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "ITERATIONS = (len(dev_data) // BATCH_SIZE) + 1\n",
    "\n",
    "with tf.Session() as session:\n",
    "    sensebert_model = SenseBert(\"sensebert-large-uncased\", session=session)  # or sensebert-large-uncased\n",
    "    \n",
    "    \n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    \n",
    "    for i in range(ITERATIONS):\n",
    "        start_idx = i * BATCH_SIZE\n",
    "        end_idx = min((i+1) * BATCH_SIZE, len(dev_data))\n",
    "    #     print(start_idx, end_idx)\n",
    "        sentences = []\n",
    "        locations = []\n",
    "        target_words = []\n",
    "        poses = []\n",
    "        for j in range(start_idx, end_idx):\n",
    "            target_words.append(dev_data[j][0])\n",
    "            target_words.append(dev_data[j][0])\n",
    "            sentences.append(dev_data[j][1])\n",
    "            sentences.append(dev_data[j][2])\n",
    "            locations.append(dev_data[j][3])\n",
    "            locations.append(dev_data[j][4])\n",
    "            poses.append(dev_data[j][5].lower())\n",
    "            poses.append(dev_data[j][5].lower())\n",
    "    #     print(sentences)\n",
    "        input_ids, input_mask = sensebert_model.tokenize(sentences)\n",
    "\n",
    "\n",
    "        found_indices = []\n",
    "        found_words = []\n",
    "        ## check that loc1, loc2 are good positions\n",
    "        for idx, input_id in enumerate(input_ids):\n",
    "            tokenized = sensebert_model.tokenizer.convert_ids_to_tokens(input_id)\n",
    "            target_idx = int(locations[idx])+1\n",
    "            found_indices.append(target_idx)\n",
    "            found_words.append(tokenized[target_idx])\n",
    "\n",
    "    #     print(found_indices)\n",
    "    #     print(found_words)\n",
    "\n",
    "        for j in range(0, len(sentences), 2):\n",
    "\n",
    "            if WordNetLemmatizer().lemmatize(found_words[j], pos=poses[j]) != WordNetLemmatizer().lemmatize(found_words[j+1], pos=poses[j]):\n",
    "\n",
    "                ## lemmatize sentences, and keyword\n",
    "                tokenized_1 = sensebert_model.tokenizer.convert_ids_to_tokens(input_ids[j])\n",
    "                tokenized_2 = sensebert_model.tokenizer.convert_ids_to_tokens(input_ids[j+1])\n",
    "\n",
    "                tokenized_1_stem = [ps.stem(w) for w in tokenized_1]\n",
    "                tokenized_2_stem = [ps.stem(w) if w!= \"bought\" else \"buy\" for w in tokenized_2]\n",
    "                tokenized_2_stem = [w if w!=\"felt\" else \"feel\" for w in tokenized_2_stem]\n",
    "                tokenized_2_stem = [w if w!=\"ve\" else \"have\" for w in tokenized_2_stem]\n",
    "                tokenized_2_stem = [w if w!=\"men\" else \"man\" for w in tokenized_2_stem]\n",
    "                tokenized_2_stem = [w if w!=\"shook\" else \"shake\" for w in tokenized_2_stem]\n",
    "                tokenized_2_stem = [w if w!=\"drank\" else \"drink\" for w in tokenized_2_stem]\n",
    "                tokenized_2_stem = [w if w!=\"sold\" else \"sell\" for w in tokenized_2_stem]\n",
    "                \n",
    "                key_word = ps.stem(target_words[j])\n",
    "\n",
    "    #             print(target_words[j])\n",
    "    #             print(key_word)\n",
    "    #             print(tokenized_1, tokenized_2)\n",
    "\n",
    "    #             print(tokenized_1.index(key_word))\n",
    "    #             print(tokenized_2.index(key_word))\n",
    "                try:\n",
    "                    found_indices[j] = tokenized_1_stem.index(key_word)\n",
    "                    found_indices[j+1] = tokenized_2_stem.index(key_word)\n",
    "                    found_words[j] = tokenized_1[found_indices[j]]\n",
    "                    found_words[j+1] = tokenized_2[found_indices[j+1]]\n",
    "                except:\n",
    "                    print(input_ids[j])\n",
    "                    print(input_ids[j+1])\n",
    "                    print(tokenized_1_stem)\n",
    "                    print(tokenized_2_stem)\n",
    "                    print(key_word)\n",
    "\n",
    "                ## find keyword in lemmatized sentences\n",
    "\n",
    "    #             print(target_words[j])\n",
    "    #             print(target_words[j+1])\n",
    "\n",
    "    #     print(found_indices)\n",
    "    #     print(found_words)\n",
    "#         print(len(sentences))\n",
    "        input_ids, input_mask = sensebert_model.tokenize(sentences)\n",
    "        model_outputs = sensebert_model.run(input_ids, input_mask)\n",
    "        contextualized_embeddings, mlm_logits, supersense_logits = model_outputs  # these are NumPy arrays\n",
    "#         print(supersense_logits.shape)\n",
    "        \n",
    "        for j in range(0, len(sentences), 2):\n",
    "            \n",
    "            pred_1 = sensebert_model.tokenizer.convert_ids_to_senses([np.argmax(supersense_logits[j][found_indices[j]])])\n",
    "            pred_2 = sensebert_model.tokenizer.convert_ids_to_senses([np.argmax(supersense_logits[j+1][found_indices[j+1]])])\n",
    "            \n",
    "            if start_idx==0:\n",
    "                print(sentences[j], sentences[j+1])\n",
    "#                 print(sensebert_model.tokenize(sentences[j]), sensebert_model.tokenize(sentences[j+1]))\n",
    "#                 print(found_indices[j], found_indices[j+1])\n",
    "                print(found_words[j], found_words[j+1])\n",
    "                print(pred_1[0], pred_2[0])\n",
    "                print(f'prediction: {pred_1[0]==pred_2[0]}')\n",
    "                print(f'actual: {dev_gold[start_idx+j//2]}')\n",
    "                print()\n",
    "            \n",
    "            if pred_1[0] == pred_2[0]:\n",
    "                if dev_gold[start_idx+j//2] == \"True\":\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FP += 1\n",
    "            else:\n",
    "                if dev_gold[start_idx+j//2] == \"True\":\n",
    "                    FN += 1\n",
    "                else:\n",
    "                    TN += 1\n",
    "        \n",
    "\n",
    "    print(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-washington",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p37)",
   "language": "python",
   "name": "conda_tensorflow_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
